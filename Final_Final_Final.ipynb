{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Classification with Machine Learning\n",
    "## Data Science Project Workflow\n",
    "\n",
    "### Project Overview\n",
    "- **Objective**: This project addresses the growing need for efficient waste management and recycling \n",
    "by enabling accurate garbage classification, which can be integrated into smart waste management \n",
    "systems.\n",
    "- **Milestones**: Data Collection, Exploration, Preprocessing, Advanced Analysis, Model Development, Deployment, and Final Documentation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Team Information\n",
    "\n",
    "### Team Members\n",
    "- **Name**: [Mohamed Mahdy Mohamed]  \n",
    "  **Email**: [nagy1018078@gmail.com]  \n",
    "  \n",
    "- **Name**: [Menna Khaled Saad]  \n",
    "  **Email**: [mennakhlaled231@gmail.com]  \n",
    "\n",
    "- **Name**: [Rawan Mohamed Taha]  \n",
    "  **Email**: [rm086334556@gmail.com]  \n",
    "  \n",
    "- **Name**: [Hagar Essam]  \n",
    "  **Email**: [essamhager974@gmail.com]  \n",
    "\n",
    "- **Name**: [Mohamed Abdelwahed Mohamed]  \n",
    "  **Email**: [ma6639@fayoum.edu.eg]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Milestone 1: Data Collection, Exploration, and Preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup and Data Download"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import zipfile\n",
    "import hashlib\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "# Image handling\n",
    "from PIL import Image\n",
    "\n",
    "# Web scraping for image data\n",
    "from icrawler.builtin import BingImageCrawler\n",
    "\n",
    "# Data processing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Dash for web applications\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, Dash\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import dash_table\n",
    "import base64\n",
    "import io\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import mlflow\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_fscore_support,\n",
    "    log_loss,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "\n",
    "# PyTorch and torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Statistical tests\n",
    "from scipy.stats import ks_2samp, wasserstein_distance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {torch.cuda.get_device_name(0) if device.type == 'cuda' else 'CPU'}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Kaggle credentials\n",
    "os.environ['KAGGLE_USERNAME'] = \"mohamedabdelmonem123\"\n",
    "os.environ['KAGGLE_KEY'] = \"5d6639c1adcad3f1291426c6e77ab109\"\n",
    "\n",
    "# Download the first dataset\n",
    "!kaggle datasets download -d farzadnekouei/trash-type-image-dataset\n",
    "\n",
    "# Download the second dataset\n",
    "!kaggle datasets download -d asdasdasasdas/garbage-classification\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Data Collection\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Unzip multiple zip files\n",
    "zip_files = ['garbage-classification.zip', 'trash-type-image-dataset.zip']\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "    print(f\"Extracted: {zip_file}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define source and target directories\n",
    "dataset_dirs = [\n",
    "    \"Garbage classification/Garbage classification\",\n",
    "    \"TrashType_Image_Dataset\"\n",
    "]\n",
    "output_dir = \"./Combined\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Track unique images using hashes\n",
    "seen_hashes = set()\n",
    "total = 0\n",
    "\n",
    "# Combine datasets with deduplication\n",
    "for dataset_dir in dataset_dirs:\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        output_class_path = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.resize((128, 128)).convert(\"RGB\")\n",
    "                    img_hash = hashlib.md5(img.tobytes()).hexdigest()\n",
    "\n",
    "                    if img_hash not in seen_hashes:\n",
    "                        seen_hashes.add(img_hash)\n",
    "                        save_path = os.path.join(output_class_path, f\"{img_hash}.jpg\")\n",
    "                        img.save(save_path)\n",
    "                        total += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {img_path}: {e}\")\n",
    "\n",
    "print(f\"Total unique images in combined dataset: {total}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Intial Data Exploration and Cleaning "
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze initial class distribution\n",
    "data_path = \"./Combined\"\n",
    "class_counts = {}\n",
    "\n",
    "# Count the number of images in each class folder\n",
    "for class_name in os.listdir(data_path):\n",
    "    class_folder = os.path.join(data_path, class_name)\n",
    "    if not class_name.startswith('.') and os.path.isdir(class_folder):\n",
    "        class_counts[class_name] = len(os.listdir(class_folder))\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(list(class_counts.items()), columns=[\"Class\", \"Image Count\"])\n",
    "\n",
    "# Display the class distribution\n",
    "print(df)\n",
    "\n",
    "# Plot the distribution using a bar plot\n",
    "sns.barplot(x=\"Class\", y=\"Image Count\", data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Number of Images per Class (Initial)\")\n",
    "plt.tight_layout()  # To avoid label cut-off\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load MobileNetV2 model from torchvision\n",
    "mobilenet_model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "mobilenet_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(mobilenet_model.last_channel, 1000),  # Adjust output if needed for direct embedding\n",
    "    nn.AdaptiveAvgPool2d(1)  # Add pooling for consistent embedding size\n",
    ")\n",
    "mobilenet_model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Function to scrape images from Bing\n",
    "def scrape_images(keyword, output_dir, num_images):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    crawler = BingImageCrawler(storage={'root_dir': output_dir})\n",
    "    crawler.crawl(keyword=keyword, max_num=num_images)\n",
    "\n",
    "# Function to extract image embeddings using MobileNetV2\n",
    "def extract_embedding(img_path):\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Extract features using MobileNetV2\n",
    "        with torch.no_grad():\n",
    "            features = mobilenet_model.features(img_tensor)\n",
    "            embedding = torch.mean(features, dim=[2, 3])  # Global average pooling\n",
    "\n",
    "        return embedding.squeeze().numpy()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting embedding for {img_path}: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scrape missing images for underrepresented classes\n",
    "to_scrape = {\n",
    "    'metal': 90,\n",
    "    'plastic': 20,\n",
    "    'cardboard': 97,\n",
    "}\n",
    "\n",
    "keywords = {\n",
    "    'metal': 'metal waste trash',\n",
    "    'plastic': 'plastic waste trash',\n",
    "    'cardboard': 'cardboard waste recycling',\n",
    "}\n",
    "\n",
    "scraping_output_dir = \"./scraping\"\n",
    "os.makedirs(scraping_output_dir, exist_ok=True)\n",
    "\n",
    "for class_name, num_images in to_scrape.items():\n",
    "    print(f\"Scraping {num_images} images for class: {class_name}\")\n",
    "    class_output_dir = os.path.join(scraping_output_dir, class_name)\n",
    "    scrape_images(keyword=keywords[class_name], output_dir=class_output_dir, num_images=num_images)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine original and scraped datasets, removing duplicates via image hash\n",
    "dataset_dirs = [\n",
    "    \"./Combined\",\n",
    "    \"./scraping\"\n",
    "]\n",
    "output_dir = \"./combine&scraping\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "seen_hashes = set()\n",
    "unique_count = 0\n",
    "\n",
    "for dataset_dir in dataset_dirs:\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        output_class_path = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.resize((128, 128)).convert(\"RGB\")\n",
    "                    img_hash = hashlib.md5(img.tobytes()).hexdigest()\n",
    "\n",
    "                    if img_hash in seen_hashes:\n",
    "                        continue\n",
    "\n",
    "                    seen_hashes.add(img_hash)\n",
    "                    save_path = os.path.join(output_class_path, f\"{img_hash}.jpg\")\n",
    "                    img.save(save_path)\n",
    "                    unique_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "print(f\"Total unique images after including scraped data: {unique_count}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze class distribution after combining scraped images\n",
    "data_path = \"./combine&scraping\"\n",
    "class_counts = {}\n",
    "\n",
    "for class_name in os.listdir(data_path):\n",
    "    class_folder = os.path.join(data_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        class_counts[class_name] = len(os.listdir(class_folder))\n",
    "\n",
    "df = pd.DataFrame(class_counts.items(), columns=[\"Class\", \"Image Count\"])\n",
    "print(df)\n",
    "\n",
    "# Plot the updated class distribution\n",
    "sns.barplot(x=\"Class\", y=\"Image Count\", data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Number of Images per Class (After Scraping)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove Corrupted Images\n",
    "dataset_path = \"./combine&scraping\"\n",
    "\n",
    "def remove_corrupted_images():\n",
    "    print(\"Removing corrupted images...\")\n",
    "    for class_dir in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for img_file in tqdm(os.listdir(class_path), desc=f\"Checking {class_dir}\"):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()\n",
    "            except (IOError, OSError):\n",
    "                print(f\"Removing corrupted: {img_path}\")\n",
    "                os.remove(img_path)\n",
    "\n",
    "remove_corrupted_images()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Loading Data with Pytorch"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load Dataset with PyTorch's ImageFolder and DataLoader\n",
    "dataset_path = \"./combine&scraping\"\n",
    "img_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset using ImageFolder\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Extract class names and number of classes\n",
    "class_names = dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Total number of samples: {len(dataset)}\")\n",
    "print(f\"Number of batches per epoch: {len(dataloader)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2: Advanced Data Analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Mislabeled Image Detection"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class QuickCNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_size=128):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (img_size // 4) * (img_size // 4), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "def train_quick_model(dataloader, num_classes, epochs=3):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = QuickCNN(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "        print(f'Epoch {epoch+1} Loss: {epoch_loss:.4f} Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    return model, dataloader.dataset.classes\n",
    "\n",
    "\n",
    "quick_model, class_names = train_quick_model(dataloader, num_classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter potentially mislabeled images\n",
    "def filter_mislabeled(model, class_names, dataset_path, img_size=(128, 128), min_conf_threshold=0.7):\n",
    "    \"\"\"Filter potentially mislabeled images based on model predictions.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        class_names: List of class names\n",
    "        dataset_path: Path to dataset directory\n",
    "        img_size: Target image size (default: (128, 128))\n",
    "        min_conf_threshold: Minimum confidence threshold for considering mislabeling (default: 0.7)\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    transform_single = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    mislabeled_count = 0\n",
    "\n",
    "    for class_dir in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_dir)\n",
    "\n",
    "        if not os.path.isdir(class_path) or class_dir.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        for img_file in tqdm(os.listdir(class_path),\n",
    "                             desc=f\"Processing {class_dir}\"):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_tensor = transform_single(img).unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model(img_tensor)\n",
    "                    probabilities = torch.softmax(output, dim=1)\n",
    "                    max_prob, predicted_idx = torch.max(probabilities, 1)\n",
    "                    predicted_class = class_names[predicted_idx.item()]\n",
    "                    confidence = max_prob.item()\n",
    "\n",
    "                if (predicted_class != class_dir and\n",
    "                        confidence > min_conf_threshold):\n",
    "                    print(f\"Mismatch: {img_file} - Predicted: {predicted_class}, \"\n",
    "                          f\"Actual: {class_dir}, Confidence: {confidence:.2f}\")\n",
    "                    os.remove(img_path)\n",
    "                    mislabeled_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "    print(f\"Found and removed {mislabeled_count} potentially mislabeled images.\")\n",
    "\n",
    "\n",
    "filter_mislabeled(quick_model, class_names, dataset_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Data Splitting and Augmentation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze class distribution after filtering\n",
    "def analyze_class_distribution(data_path=\"./combine&scraping\"):\n",
    "    \"\"\"Analyze and visualize class distribution in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the dataset directory (default: \"./combine&scraping\")\n",
    "    \"\"\"\n",
    "    # Count images per class\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(data_path):\n",
    "        class_dir = os.path.join(data_path, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            try:\n",
    "                class_counts[class_name] = len([\n",
    "                    f for f in os.listdir(class_dir)\n",
    "                    if os.path.isfile(os.path.join(class_dir, f))\n",
    "                ])\n",
    "            except OSError as e:\n",
    "                print(f\"Error accessing {class_dir}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Create and display dataframe\n",
    "    df = pd.DataFrame.from_dict(class_counts,\n",
    "                                orient='index',\n",
    "                                columns=['Image Count'])\n",
    "    df.index.name = 'Class'\n",
    "    df.reset_index(inplace=True)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Visualize distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=\"Class\", y=\"Image Count\", data=df)\n",
    "    ax.set_title(\"Class Distribution After Filtering\", pad=20)\n",
    "    ax.set_xlabel(\"Class\", labelpad=10)\n",
    "    ax.set_ylabel(\"Number of Images\", labelpad=10)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "analyze_class_distribution()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split Data into Train, Validation, and Test sets\n",
    "BASE_DIR = './dataset_split'\n",
    "DATA_PATH = \"./combine&scraping\"\n",
    "TRAIN_SPLIT, VAL_SPLIT = 0.7, 0.15\n",
    "\n",
    "# Create base directories\n",
    "train_dir, val_dir, test_dir = [os.path.join(BASE_DIR, x) for x in ['train', 'val', 'test']]\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Get class names (excluding hidden directories)\n",
    "class_names = [d for d in os.listdir(DATA_PATH) if not d.startswith('.')]\n",
    "\n",
    "# Split data for each class\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(DATA_PATH, class_name)\n",
    "    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n_total = len(images)\n",
    "    n_train = int(TRAIN_SPLIT * n_total)\n",
    "    n_val = int(VAL_SPLIT * n_total)\n",
    "\n",
    "    # Define splits\n",
    "    splits = {\n",
    "        train_dir: images[:n_train],\n",
    "        val_dir: images[n_train:n_train + n_val],\n",
    "        test_dir: images[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    # Copy files to respective directories\n",
    "    for split_dir, split_images in splits.items():\n",
    "        class_split_path = os.path.join(split_dir, class_name)\n",
    "        os.makedirs(class_split_path, exist_ok=True)\n",
    "\n",
    "        for img in tqdm(split_images,\n",
    "                        desc=f'Splitting {class_name} -> {os.path.basename(split_dir)}',\n",
    "                        leave=False):\n",
    "            src = os.path.join(class_path, img)\n",
    "            dst = os.path.join(class_split_path, img)\n",
    "            shutil.copy2(src, dst)  # copy2 preserves metadata\n",
    "\n",
    "print(\"\\nData splitting completed successfully.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data Normalization and Augmentation for PyTorch\n",
    "DATA_DIR = './dataset_split'\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "NORMALIZATION_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZATION_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Define paths\n",
    "train_dir = os.path.join(DATA_DIR, 'train')\n",
    "val_dir = os.path.join(DATA_DIR, 'val')\n",
    "test_dir = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# Common transforms\n",
    "base_transforms = [\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORMALIZATION_MEAN, std=NORMALIZATION_STD)\n",
    "]\n",
    "\n",
    "# Training transforms with augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.2, 0.2),\n",
    "        scale=(0.8, 1.2)\n",
    "    ),\n",
    "    *base_transforms\n",
    "])\n",
    "\n",
    "# Validation and test transforms\n",
    "val_transforms = transforms.Compose(base_transforms)\n",
    "test_transforms = transforms.Compose(base_transforms)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of validation batches:\", len(val_loader))\n",
    "print(\"Number of test batches:\", len(test_loader))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature Extraction and Visualization"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sample images from each class\n",
    "data_path = \"./combine&scraping\"\n",
    "class_names = [d for d in os.listdir(data_path) if not d.startswith('.')]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(data_path, class_name)\n",
    "\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    images = [\n",
    "        f for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
    "    ]\n",
    "\n",
    "    if not images:\n",
    "        continue\n",
    "\n",
    "    img_name = random.choice(images)\n",
    "    img_path = os.path.join(class_dir, img_name)\n",
    "\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        plt.subplot(2, 3, idx + 1)\n",
    "        plt.imshow(np.array(img))\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {img_path} - {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Embedding Extraction and PCA Visualization (PyTorch)\n",
    "def extract_pytorch_embedding(img_path, model, transform, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Extract embedding from an image using PyTorch model.\n",
    "    \n",
    "    Args:\n",
    "        img_path: Path to image file\n",
    "        model: Pretrained PyTorch model\n",
    "        transform: Image transformations\n",
    "        device: Device to run model on\n",
    "        \n",
    "    Returns:\n",
    "        Numpy array of embedding or None if error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = model.features(img_tensor)\n",
    "            embedding = torch.mean(features, dim=[2, 3])\n",
    "        return embedding.squeeze().cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting embedding from {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = './dataset_split'\n",
    "MAX_IMAGES_PER_CLASS = 120\n",
    "IMAGE_EXTS = ('.jpg', '.png', '.jpeg')\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mobilenet_model = mobilenet_model.to(device)\n",
    "mobilenet_model.eval()\n",
    "\n",
    "# Define transforms\n",
    "pca_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Collect embeddings\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for split_name in ['train', 'test', 'val']:\n",
    "    split_folder = os.path.join(DATA_PATH, split_name)\n",
    "    print(f\"Processing {split_name} folder...\")\n",
    "\n",
    "    for class_name in os.listdir(split_folder):\n",
    "        class_folder = os.path.join(split_folder, class_name)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            continue\n",
    "\n",
    "        img_files = [\n",
    "                        f for f in os.listdir(class_folder)\n",
    "                        if f.lower().endswith(IMAGE_EXTS)\n",
    "                    ][:MAX_IMAGES_PER_CLASS]\n",
    "\n",
    "        print(f\"Processing class: {class_name} with {len(img_files)} images.\")\n",
    "\n",
    "        for img_name in img_files:\n",
    "            img_path = os.path.join(class_folder, img_name)\n",
    "            emb = extract_pytorch_embedding(img_path, mobilenet_model, pca_transform, device)\n",
    "            if emb is not None:\n",
    "                embeddings.append(emb)\n",
    "                labels.append(class_name)\n",
    "\n",
    "print(f\"Total embeddings collected: {len(embeddings)}\")\n",
    "\n",
    "# Visualize with PCA\n",
    "if embeddings:\n",
    "    X_pca = PCA(n_components=2).fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_name in sorted(set(labels)):\n",
    "        idxs = [i for i, l in enumerate(labels) if l == class_name]\n",
    "        plt.scatter(X_pca[idxs, 0], X_pca[idxs, 1], label=class_name)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(\"PCA of Image Embeddings (PyTorch MobileNetV2)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No embeddings to visualize.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature Extraction for Classical ML"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data Generator for Training with ResNet50 (PyTorch)\n",
    "DATA_ROOT = './dataset_split'\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, 'train')\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "NORMALIZATION_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZATION_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training transforms with augmentations\n",
    "train_transforms_resnet = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.2, 0.2),\n",
    "        scale=(0.8, 1.2)\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=NORMALIZATION_MEAN,\n",
    "        std=NORMALIZATION_STD\n",
    "    )\n",
    "])\n",
    "\n",
    "# Create dataset and data loader\n",
    "train_dataset_resnet = datasets.ImageFolder(\n",
    "    TRAIN_DIR,\n",
    "    transform=train_transforms_resnet\n",
    ")\n",
    "\n",
    "train_loader_resnet = DataLoader(\n",
    "    train_dataset_resnet,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(\"Train dataset size (ResNet):\", len(train_dataset_resnet))\n",
    "print(\"Number of training batches (ResNet):\", len(train_loader_resnet))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize a batch of training data (PyTorch)\n",
    "NUM_IMAGES_TO_DISPLAY = 9\n",
    "GRID_SHAPE = (3, 3)\n",
    "PLOT_SIZE = (10, 10)\n",
    "NORMALIZATION_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "NORMALIZATION_STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Get a batch of images\n",
    "images, labels = next(iter(train_loader_resnet))\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=PLOT_SIZE)\n",
    "for i in range(min(NUM_IMAGES_TO_DISPLAY, len(images))):\n",
    "    # Prepare image\n",
    "    img = images[i].permute(1, 2, 0).numpy()\n",
    "    img = (img * NORMALIZATION_STD) + NORMALIZATION_MEAN\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Get class info\n",
    "    class_idx = labels[i].item()\n",
    "    class_name = train_dataset_resnet.classes[class_idx]\n",
    "\n",
    "    # Plot\n",
    "    plt.subplot(*GRID_SHAPE, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_name, fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_resnet_embedding_pytorch(img_path, model, transform, device=None):\n",
    "    \"\"\"Extract feature embeddings from an image using a ResNet model.\n",
    "    \n",
    "    Args:\n",
    "        img_path (str): Path to the input image file\n",
    "        model (torch.nn.Module): Pretrained ResNet model\n",
    "        transform (torchvision.transforms): Image transformations to apply\n",
    "        device (str, optional): Device to run model on. Defaults to 'cuda' if available, else 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Flattened feature vector, or None if error occurs\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    try:\n",
    "        # Load and transform image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = model(img_tensor)\n",
    "\n",
    "        # Return flattened features as numpy array\n",
    "        return features.flatten(start_dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting ResNet embedding from {img_path}: {str(e)}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature Extraction and Preprocessing for Classical ML Models (PyTorch ResNet50)\n",
    "\n",
    "# Initialize model\n",
    "resnet50_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "resnet50_model = nn.Sequential(*list(resnet50_model.children())[:-1])\n",
    "resnet50_model = resnet50_model.eval().to(device)\n",
    "\n",
    "def extract_resnet_features(data_path='./dataset_split', img_size=128, test_size=0.2, random_state=42):\n",
    "    \"\"\"Extract and process ResNet50 features from image dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to dataset directory\n",
    "        img_size (int): Target image size (default: 128)\n",
    "        test_size (float): Test set proportion (default: 0.2)\n",
    "        random_state (int): Random seed (default: 42)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_train, y_test, label_encoder)\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    img_extensions = ('.jpg', '.png', '.jpeg')\n",
    "    splits = ['train', 'test']\n",
    "\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Extract embeddings\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for split_name in splits:\n",
    "        split_dir = os.path.join(data_path, split_name)\n",
    "        for class_name in os.listdir(split_dir):\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "\n",
    "            img_files = [f for f in os.listdir(class_dir)\n",
    "                         if f.lower().endswith(img_extensions)]\n",
    "\n",
    "            for img_file in img_files:\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                emb = extract_resnet_embedding_pytorch(img_path, resnet50_model, transform, device)\n",
    "                if emb is not None:\n",
    "                    embeddings.append(emb.flatten())\n",
    "                    labels.append(class_name)\n",
    "\n",
    "    # Preprocess features\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(embeddings)\n",
    "\n",
    "    # Dimensionality reduction\n",
    "    pca = PCA(n_components=100)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=50)\n",
    "    X_features = selector.fit_transform(X_pca, y)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_features, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nFeature Extraction Summary:\")\n",
    "    print(f\"- Total samples: {len(embeddings)}\")\n",
    "    print(f\"- Classes: {len(le.classes_)}\")\n",
    "    print(f\"- Train shape: {X_train.shape}\")\n",
    "    print(f\"- Test shape: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, le\n",
    "\n",
    "# Execute the pipeline\n",
    "X_train_resnet, X_test_resnet, y_train_resnet, y_test_resnet, label_encoder = extract_resnet_features()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3: Machine Learning Model Development and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Classical Machine Learning Models\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and Evaluate Classical Machine Learning Models\n",
    "models_resnet = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models_resnet.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_resnet, y_train_resnet)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_resnet = model.predict(X_test_resnet)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test_resnet, y_pred_resnet)\n",
    "    class_report = classification_report(\n",
    "        y_test_resnet,\n",
    "        y_pred_resnet,\n",
    "        target_names=label_encoder.classes_,\n",
    "        digits=2\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{name} Performance (ResNet Features):\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "# Create confusion matrix plots\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (name, model) in enumerate(models_resnet.items(), 1):\n",
    "    y_pred_resnet = model.predict(X_test_resnet)\n",
    "    cm = confusion_matrix(y_test_resnet, y_pred_resnet)\n",
    "\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_,\n",
    "        cmap='Blues'\n",
    "    )\n",
    "    plt.title(f'{name} (ResNet)')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Hyperparameter Tuning"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    # Hyperparameter Tuning (using ResNet features)\n",
    "MODEL_CONFIGS = [\n",
    "    {\n",
    "        'name': 'Logistic Regression',\n",
    "        'model': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'param_grid': {\n",
    "            'C': [0.01, 0.1, 1, 10],\n",
    "            'penalty': ['l2'],\n",
    "            'solver': ['lbfgs']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'SVM',\n",
    "        'model': SVC(probability=True, random_state=42),\n",
    "        'param_grid': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [None, 10, 20]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform tuning for each model\n",
    "tuned_models = {}\n",
    "for config in MODEL_CONFIGS:\n",
    "    grid = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['param_grid'],\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(f\"\\nTuning {config['name']}...\")\n",
    "    grid.fit(X_train_resnet, y_train_resnet)\n",
    "    tuned_models[config['name']] = grid\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best {config['name']} (ResNet):\")\n",
    "    print(f\"Parameters: {grid.best_params_}\")\n",
    "    print(f\"Validation Accuracy: {grid.best_score_:.4f}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ensemble Methods"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensemble Voting Classifier with ResNet Features\n",
    "voting_clf_resnet = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', tuned_models['Logistic Regression'].best_estimator_),\n",
    "        ('svm', tuned_models['SVM'].best_estimator_),\n",
    "        ('rf', tuned_models['Random Forest'].best_estimator_)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1  # Enable parallel processing\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "print(\"Training Voting Classifier...\")\n",
    "voting_clf_resnet.fit(X_train_resnet, y_train_resnet)\n",
    "print(\"Voting Classifier training completed.\\n\")\n",
    "\n",
    "# Generate predictions and metrics\n",
    "y_pred_voting_resnet = voting_clf_resnet.predict(X_test_resnet)\n",
    "y_proba_voting_resnet = voting_clf_resnet.predict_proba(X_test_resnet)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "acc_voting_resnet = accuracy_score(y_test_resnet, y_pred_voting_resnet)\n",
    "class_report = classification_report(\n",
    "    y_test_resnet,\n",
    "    y_pred_voting_resnet,\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "# Print comprehensive results\n",
    "print(\"=\"*60)\n",
    "print(f\"Voting Classifier Performance (ResNet Features)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {acc_voting_resnet:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    voting_clf_resnet,\n",
    "    X_test_resnet,\n",
    "    y_test_resnet,\n",
    "    display_labels=label_encoder.classes_,\n",
    "    cmap='Blues',\n",
    "    xticks_rotation=45,\n",
    "    normalize='true',\n",
    "    values_format='.2f'\n",
    ")\n",
    "plt.title(\"Voting Classifier - Normalized Confusion Matrix (ResNet Features)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional metrics\n",
    "print(\"\\nAdditional Metrics:\")\n",
    "print(f\"Log Loss: {log_loss(y_test_resnet, y_proba_voting_resnet):.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test_resnet, y_pred_voting_resnet):.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensemble Methods: Stacking Classifier (using ResNet features)\n",
    "\n",
    "stacking_clf_resnet = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', tuned_models['Logistic Regression'].best_estimator_),\n",
    "        ('svm', tuned_models['SVM'].best_estimator_),\n",
    "        ('rf', tuned_models['Random Forest'].best_estimator_)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=5\n",
    ")\n",
    "stacking_clf_resnet.fit(X_train_resnet, y_train_resnet)\n",
    "y_pred_stacking_resnet = stacking_clf_resnet.predict(X_test_resnet)\n",
    "acc_stack_resnet = accuracy_score(y_test_resnet, y_pred_stacking_resnet)\n",
    "print(f\"Stacking Classifier Accuracy (ResNet Features): {acc_stack_resnet:.2f}\")\n",
    "print(classification_report(y_test_resnet, y_pred_stacking_resnet, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrices for Ensemble Methods\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    voting_clf_resnet, X_test_resnet, y_test_resnet, display_labels=label_encoder.classes_,\n",
    "    cmap='Blues', xticks_rotation=45, ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Voting Classifier (ResNet)\")\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    stacking_clf_resnet, X_test_resnet, y_test_resnet, display_labels=label_encoder.classes_,\n",
    "    cmap='Greens', xticks_rotation=45, ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Stacking Classifier (ResNet)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "SAVE_DIR = 'saved_models'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def save_model_with_metadata(model, model_name, model_type='pytorch'):\n",
    "    \"\"\"Save a model with metadata and return the save path.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{model_name}_{timestamp}.{'pth' if model_type == 'pytorch' else 'joblib'}\"\n",
    "    save_path = os.path.join(SAVE_DIR, filename)\n",
    "\n",
    "    try:\n",
    "        if model_type == 'pytorch':\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            joblib.dump(model, save_path)\n",
    "\n",
    "        print(f\"Successfully saved {model_name} to: {save_path}\")\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Save PyTorch models\n",
    "quick_model_path = save_model_with_metadata(quick_model, 'quick_cnn_model')\n",
    "mobilenet_path = save_model_with_metadata(mobilenet_model.features, 'mobilenetv2_features')\n",
    "resnet50_path = save_model_with_metadata(resnet50_model, 'resnet50_features')\n",
    "\n",
    "# Save classical ML models\n",
    "save_model_with_metadata(models_resnet, 'classical_ml_models_resnet', 'joblib')\n",
    "save_model_with_metadata(tuned_models['Logistic Regression'], 'grid_lr_resnet', 'joblib')\n",
    "save_model_with_metadata(tuned_models['SVM'], 'grid_svm_resnet', 'joblib')\n",
    "save_model_with_metadata(tuned_models['Random Forest'], 'grid_rf_resnet', 'joblib')\n",
    "\n",
    "# Save ensemble models\n",
    "save_model_with_metadata(voting_clf_resnet, 'voting_clf_resnet', 'joblib')\n",
    "save_model_with_metadata(stacking_clf_resnet, 'stacking_clf_resnet', 'joblib')\n",
    "\n",
    "# Save label encoders and other metadata\n",
    "joblib.dump(label_encoder, os.path.join(SAVE_DIR, 'label_encoder.joblib'))\n",
    "print(\"Label encoders saved.\")\n",
    "\n",
    "# Create a README file with model information\n",
    "with open(os.path.join(SAVE_DIR, 'README.md'), 'w') as f:\n",
    "    f.write(\"# Model Storage Information\\n\\n\")\n",
    "    f.write(f\"## Saved on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"### Models Included:\\n\")\n",
    "    f.write(\"- Quick CNN Model\\n\")\n",
    "    f.write(\"- MobileNetV2 Feature Extractor\\n\")\n",
    "    f.write(\"- ResNet50 Feature Extractor\\n\")\n",
    "    f.write(\"- Classical ML Models (Logistic Regression, SVM, Random Forest)\\n\")\n",
    "    f.write(\"- Tuned Classical ML Models\\n\")\n",
    "    f.write(\"- Voting Classifier\\n\")\n",
    "    f.write(\"- Stacking Classifier\\n\")\n",
    "    f.write(\"- Label Encoders\\n\")\n",
    "print(\"README file created in saved_models directory.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Neural Network Models"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, num_classes, dropout_rate=0.2):\n",
    "        \"\"\"Initialize a simple feedforward neural network.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Size of input features (flattened)\n",
    "            hidden_units (list): List of integers specifying hidden layer sizes\n",
    "            num_classes (int): Number of output classes\n",
    "            dropout_rate (float): Dropout probability (default: 0.2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Input validation\n",
    "        if not isinstance(hidden_units, (list, tuple)):\n",
    "            raise ValueError(\"hidden_units must be a list or tuple of integers\")\n",
    "        if not all(isinstance(x, int) and x > 0 for x in hidden_units):\n",
    "            raise ValueError(\"All hidden units must be positive integers\")\n",
    "\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "\n",
    "        # Build hidden layers\n",
    "        for i, units in enumerate(hidden_units):\n",
    "            layers.append(nn.Linear(in_features, units))\n",
    "            layers.append(nn.BatchNorm1d(units))  # Added batch normalization\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))  # Added dropout\n",
    "            in_features = units\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(in_features, num_classes))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Kaiming initialization.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, *)\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Output logits\n",
    "        \"\"\"\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        return self.network(x)\n",
    "\n",
    "# Determine input size safely\n",
    "def get_input_size(dataset):\n",
    "    \"\"\"Get flattened input size from dataset.\"\"\"\n",
    "    try:\n",
    "        sample = next(iter(DataLoader(dataset, batch_size=1)))[0]\n",
    "        return sample.view(-1).shape[0]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Could not determine input size: {str(e)}\")\n",
    "\n",
    "# Initialize model\n",
    "try:\n",
    "    flat_input_size = get_input_size(train_dataset)\n",
    "    ann_model = SimpleANN(\n",
    "        input_size=flat_input_size,\n",
    "        hidden_units=[128, 64],\n",
    "        num_classes=num_classes,\n",
    "        dropout_rate=0.3  # Slightly higher dropout for regularization\n",
    "    )\n",
    "    print(f\"Initialized ANN model with input size {flat_input_size}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing ANN model: {str(e)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_size=128, dropout_rate=0.3):\n",
    "        \"\"\"Initialize a CNN model for image classification.\n",
    "        \n",
    "        Args:\n",
    "            num_classes (int): Number of output classes\n",
    "            img_size (int): Input image size (default: 128)\n",
    "            dropout_rate (float): Dropout probability (default: 0.3)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Calculate flattened size\n",
    "        self.flatten = nn.Flatten()\n",
    "        flattened_size = 64 * (img_size // 4) * (img_size // 4)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.BatchNorm1d(128),  # Added batch normalization\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),  # Added dropout\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Kaiming initialization.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 3, img_size, img_size)\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Output logits\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "cnn_model = CNN(\n",
    "    num_classes=num_classes,\n",
    "    img_size=128,  \n",
    "    dropout_rate=0.3  \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def initialize_googlenet(num_classes, pretrained=True, freeze_backbone=False):\n",
    "    \"\"\"Initialize and configure a GoogLeNet model for transfer learning.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of output classes\n",
    "        pretrained (bool): Whether to use pretrained weights (default: True)\n",
    "        freeze_backbone (bool): Whether to freeze feature extractor (default: False)\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: Configured GoogLeNet model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load pretrained GoogLeNet\n",
    "        model = models.googlenet(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "\n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Modify the final fully connected layer\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        # Modify auxiliary classifiers if they exist\n",
    "        if hasattr(model, 'aux1') and model.aux1 is not None:\n",
    "            model.aux1.fc2 = nn.Linear(model.aux1.fc2.in_features, num_classes)\n",
    "        if hasattr(model, 'aux2') and model.aux2 is not None:\n",
    "            model.aux2.fc2 = nn.Linear(model.aux2.fc2.in_features, num_classes)\n",
    "\n",
    "        # Initialize new layers properly\n",
    "        nn.init.kaiming_normal_(model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if model.fc.bias is not None:\n",
    "            nn.init.constant_(model.fc.bias, 0)\n",
    "\n",
    "        print(f\"Initialized GoogLeNet model with {num_classes} output classes\")\n",
    "        print(f\"Backbone {'frozen' if freeze_backbone else 'trainable'}\")\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing GoogLeNet: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "googlenet_model = initialize_googlenet(\n",
    "    num_classes=10,  # Your number of classes\n",
    "    pretrained=True,\n",
    "    freeze_backbone=True  # Set to False if you want to fine-tune the entire model\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, grad_clip=None):\n",
    "    \"\"\"Train model for one epoch with optional gradient clipping.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping if specified\n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def evaluate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, device,\n",
    "                       epochs=50, patience=5, scheduler=None, grad_clip=None):\n",
    "    \"\"\"Train model with early stopping and optional learning rate scheduling.\"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': []\n",
    "    }\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, grad_clip\n",
    "        )\n",
    "        val_loss, val_acc = evaluate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        # Step the learning rate scheduler if provided\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f'\\nEarly stopping after {epoch+1} epochs!')\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "        # Print epoch summary\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch {epoch+1}/{epochs}: '\n",
    "              f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | '\n",
    "              f'Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "              f'LR: {lr:.2e}')\n",
    "\n",
    "    return history, best_model_state\n",
    "\n",
    "def cross_validate(model_type, dataset, val_dataset, folds=5, epochs=50,\n",
    "                   learning_rate=0.001, patience=5, batch_size=32,\n",
    "                   device=None, model_args=None):\n",
    "    \"\"\"Perform k-fold cross validation with consistent validation set.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if model_args is None:\n",
    "        model_args = {}\n",
    "\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    best_models = []\n",
    "\n",
    "    for fold, (train_idx, _) in enumerate(kf.split(range(len(dataset)))):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Fold {fold+1}/{folds}\")\n",
    "        print(f\"{'='*40}\")\n",
    "\n",
    "        # Create data loaders\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        train_loader = DataLoader(\n",
    "            dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "            num_workers=4, pin_memory=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=batch_size,\n",
    "            num_workers=4, pin_memory=True\n",
    "        )\n",
    "\n",
    "        # Initialize model\n",
    "        if model_type.__name__ == 'SimpleANN':\n",
    "            model = SimpleANN(**model_args).to(device)\n",
    "        elif model_type.__name__ == 'CNN':\n",
    "            model = CNN(**model_args).to(device)\n",
    "        elif model_type.__name__ == 'GoogLeNet':\n",
    "            model = initialize_googlenet(**model_args).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type.__name__}\")\n",
    "\n",
    "        # Training setup\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, 'min', patience=patience//2, factor=0.5, verbose=True\n",
    "        )\n",
    "\n",
    "        # Train and evaluate\n",
    "        history, best_state = train_and_evaluate(\n",
    "            model, train_loader, val_loader, criterion, optimizer, device,\n",
    "            epochs=epochs, patience=patience, scheduler=scheduler,\n",
    "            grad_clip=1.0  # Mild gradient clipping\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        model.load_state_dict(best_state)\n",
    "        _, val_acc = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        fold_results.append(val_acc)\n",
    "        best_models.append(deepcopy(model.state_dict()))\n",
    "\n",
    "        print(f\"\\nFold {fold+1} Results:\")\n",
    "        print(f\"- Best Val Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"- Final LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Final summary\n",
    "    mean_val_acc = np.mean(fold_results)\n",
    "    std_val_acc = np.std(fold_results)\n",
    "\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Cross-Validation Complete ({folds} folds)\")\n",
    "    print(f\"{'='*40}\")\n",
    "    print(f\"Mean Val Accuracy: {mean_val_acc:.4f} ± {std_val_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'fold_accuracies': fold_results,\n",
    "        'best_model_states': best_models,\n",
    "        'mean_accuracy': mean_val_acc,\n",
    "        'std_accuracy': std_val_acc\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cross-Validation\n",
    "def run_comprehensive_cv(train_dataset, val_dataset, num_classes, img_size=128):\n",
    "    \"\"\"Run cross-validation for all model types with optimal settings.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting Comprehensive Cross-Validation on {device}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Configuration for each model type\n",
    "    model_configs = [\n",
    "        {\n",
    "            'name': 'SimpleANN',\n",
    "            'type': SimpleANN,\n",
    "            'args': {\n",
    "                'input_size': img_size * img_size * 3,  # Flattened image size\n",
    "                'hidden_units': [128, 64],\n",
    "                'num_classes': num_classes,\n",
    "                'dropout_rate': 0.3\n",
    "            },\n",
    "            'train_params': {\n",
    "                'epochs': 30,\n",
    "                'learning_rate': 0.001,\n",
    "                'batch_size': 64,\n",
    "                'patience': 5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'CNN',\n",
    "            'type': CNN,\n",
    "            'args': {\n",
    "                'num_classes': num_classes,\n",
    "                'img_size': img_size,\n",
    "                'dropout_rate': 0.3\n",
    "            },\n",
    "            'train_params': {\n",
    "                'epochs': 30,\n",
    "                'learning_rate': 0.001,\n",
    "                'batch_size': 32,\n",
    "                'patience': 5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'GoogLeNet',\n",
    "            'type': models.GoogLeNet,\n",
    "            'args': {\n",
    "                'num_classes': num_classes,\n",
    "                'pretrained': True,\n",
    "                'freeze_backbone': True  # Freeze feature extractor\n",
    "            },\n",
    "            'train_params': {\n",
    "                'epochs': 15,\n",
    "                'learning_rate': 0.0001,  # Smaller LR for fine-tuning\n",
    "                'batch_size': 32,\n",
    "                'patience': 3\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    final_models = {}\n",
    "\n",
    "    for config in model_configs:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Running {config['name']} Cross-Validation\")\n",
    "        print(f\"{'='*40}\")\n",
    "\n",
    "        cv_result = cross_validate(\n",
    "            model_type=config['type'],\n",
    "            dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            folds=5,\n",
    "            device=device,\n",
    "            model_args=config['args'],\n",
    "            **config['train_params']\n",
    "        )\n",
    "\n",
    "        results[config['name']] = cv_result\n",
    "        final_models[config['name']] = cv_result['best_model_states'][-1]\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"\\n{config['name']} CV Results:\")\n",
    "        print(f\"- Mean Val Accuracy: {cv_result['mean_accuracy']:.4f}\")\n",
    "        print(f\"- Std Dev: {cv_result['std_accuracy']:.4f}\")\n",
    "        print(f\"- Fold Accuracies: {[f'{acc:.4f}' for acc in cv_result['fold_accuracies']]}\")\n",
    "\n",
    "    # Comparative analysis\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"Cross-Validation Summary\")\n",
    "    print(\"=\"*60)\n",
    "    for model_name, res in results.items():\n",
    "        print(f\"{model_name:<12} | Mean Acc: {res['mean_accuracy']:.4f} ± {res['std_accuracy']:.4f}\")\n",
    "\n",
    "    return results, final_models\n",
    "\n",
    "# Execute the comprehensive cross-validation\n",
    "all_results, all_models = run_comprehensive_cv(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    num_classes=num_classes,\n",
    "    img_size=128\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_on_test_with_metrics(model, test_loader, device, class_names, model_name=\"\"):\n",
    "    \"\"\"Comprehensive evaluation of model on test set with multiple metrics.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=f\"Evaluating {model_name}\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    # Handle binary vs. multi-class for ROC AUC\n",
    "    if len(class_names) > 2:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
    "        except ValueError:\n",
    "            print(f\"Warning: ROC AUC calculation failed for multi-class '{model_name}'.\")\n",
    "            roc_auc = np.nan\n",
    "    elif len(class_names) == 2:\n",
    "        roc_auc = roc_auc_score(all_labels, np.array(all_probs)[:, 1])\n",
    "    else:\n",
    "        roc_auc = np.nan # Only one class\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'balanced_accuracy': balanced_acc,\n",
    "        'roc_auc': roc_auc,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm,\n",
    "        'predictions': all_preds,\n",
    "        'probabilities': all_probs,\n",
    "        'true_labels': all_labels\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, model_name, cmap='Blues'):\n",
    "    \"\"\"Plot normalized confusion matrix with better formatting.\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap=cmap,\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar=False, linewidths=0.5, linecolor='gray')\n",
    "\n",
    "    plt.title(f'{model_name} - Normalized Confusion Matrix', pad=20, fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_all_models(models_dict, test_loader, device, class_names, img_size=128, num_classes=None):\n",
    "    \"\"\"Evaluate multiple models and generate comparative report.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model_state in models_dict.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Evaluating {model_name} on Test Set\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Instantiate the model based on the name and load the best state\n",
    "        if model_name == 'SimpleANN':\n",
    "            model = SimpleANN(input_size=img_size * img_size * 3,\n",
    "                              hidden_units=[128, 64],\n",
    "                              num_classes=num_classes,\n",
    "                              dropout_rate=0.3).to(device)\n",
    "        elif model_name == 'CNN':\n",
    "            # Create the CNN with the exact architecture used during training\n",
    "            model = CNN(num_classes=num_classes,\n",
    "                        img_size=img_size,\n",
    "                        dropout_rate=0.3).to(device)\n",
    "        elif model_name == 'CNN-RNN':\n",
    "            model = CNNRNNClassifier(num_classes=num_classes).to(device)\n",
    "        elif model_name == 'GoogLeNet':\n",
    "            model = initialize_googlenet(num_classes=num_classes).to(device)\n",
    "        else:\n",
    "            print(f\"Unknown model name: {model_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Try loading with strict=False first\n",
    "            model.load_state_dict(model_state, strict=False)\n",
    "            print(f\"Successfully loaded {model_name} with strict=False\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {model_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        model.eval()  # Set to evaluation mode\n",
    "\n",
    "        eval_results = evaluate_on_test_with_metrics(model, test_loader, device, class_names, model_name)\n",
    "        results[model_name] = eval_results\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"\\n{model_name} Test Metrics:\")\n",
    "        print(f\"- Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "        print(f\"- Balanced Accuracy: {eval_results['balanced_accuracy']:.4f}\")\n",
    "        if 'roc_auc' in eval_results:\n",
    "            print(f\"- ROC AUC: {eval_results['roc_auc']:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(eval_results['classification_report'])\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(eval_results['confusion_matrix'], class_names, model_name)\n",
    "\n",
    "    # Comparative analysis\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"Model Comparison Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Model':<15} {'Accuracy':<10} {'Balanced Acc':<12} {'ROC AUC':<10}\")\n",
    "    for model_name, res in results.items():\n",
    "        roc_auc_str = f\"{res['roc_auc']:.4f}\" if 'roc_auc' in res else \"N/A\"\n",
    "        print(f\"{model_name:<15} {res['accuracy']:.4f}     {res['balanced_accuracy']:.4f}       {roc_auc_str}\")\n",
    "\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run comprehensive evaluation using the final_models from cross-validation\n",
    "if 'all_models' in locals():\n",
    "    test_results = evaluate_all_models(\n",
    "        models_dict=all_models,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        class_names=class_names,\n",
    "        img_size=128,\n",
    "        num_classes=num_classes # Ensure num_classes is defined\n",
    "    )\n",
    "else:\n",
    "    print(\"Error: Cross-validation was not run. 'all_models' is not defined.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Hyperparameter Tuning with Optuna"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#CNN Tuning\n",
    "def objective_cnn(trial):\n",
    "    \"\"\"Optuna objective function for CNN hyperparameter optimization.\"\"\"\n",
    "    # Define hyperparameters to optimize with more sophisticated suggestions\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    num_filters_1 = trial.suggest_int(\"num_filters_1\", 16, 128, step=16)\n",
    "    num_filters_2 = trial.suggest_int(\"num_filters_2\", 32, 256, step=32)\n",
    "    fc1_units = trial.suggest_int(\"fc1_units\", 64, 512, step=64)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    # Create data loaders with suggested batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Define the CNN model with suggested hyperparameters\n",
    "    class TunedCNN(nn.Module):\n",
    "        def __init__(self, num_classes, num_filters_1, num_filters_2, fc1_units, dropout_rate):\n",
    "            super().__init__()\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, num_filters_1, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(num_filters_1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                nn.Conv2d(num_filters_1, num_filters_2, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(num_filters_2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(num_filters_2 * (img_size // 4) * (img_size // 4), fc1_units),\n",
    "                nn.BatchNorm1d(fc1_units),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(fc1_units, num_classes)\n",
    "            )\n",
    "\n",
    "            # Initialize weights\n",
    "            self._initialize_weights()\n",
    "\n",
    "        def _initialize_weights(self):\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "    # Initialize model and training components\n",
    "    model = TunedCNN(num_classes, num_filters_1, num_filters_2, fc1_units, dropout_rate).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    epochs = 15\n",
    "    best_val_accuracy = 0.0\n",
    "    patience = 3\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "    return best_val_accuracy\n",
    "\n",
    "# Train the best CNN model with full epochs\n",
    "class BestTunedCNN(nn.Module):\n",
    "    def __init__(self, num_classes, params):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, params['num_filters_1'], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(params['num_filters_1']),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(params['num_filters_1'], params['num_filters_2'], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(params['num_filters_2']),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(params['num_filters_2'] * (img_size // 4) * (img_size // 4), params['fc1_units']),\n",
    "            nn.BatchNorm1d(params['fc1_units']),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(params['dropout']),\n",
    "            nn.Linear(params['fc1_units'], num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create and run the study\n",
    "study_cnn = optuna.create_study(direction=\"maximize\")\n",
    "study_cnn.enqueue_trial({\n",
    "    'lr': 0.001,\n",
    "    'num_filters_1': 32,\n",
    "    'num_filters_2': 64,\n",
    "    'fc1_units': 128,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 64,\n",
    "    'weight_decay': 1e-4\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Optimize with pruning\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "study_cnn.optimize(objective_cnn, n_trials=50, timeout=3600, callbacks=[lambda study, trial: print(f\"Trial {trial.number} completed with value: {trial.value}\")])\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest CNN hyperparameters:\", study_cnn.best_params)\n",
    "print(\"Best validation accuracy:\", study_cnn.best_value)\n",
    "\n",
    "# Visualization\n",
    "optuna.visualization.plot_optimization_history(study_cnn).show()\n",
    "optuna.visualization.plot_param_importances(study_cnn).show()\n",
    "\n",
    "# Initialize and train the best model\n",
    "best_cnn_model = BestTunedCNN(num_classes, study_cnn.best_params).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(best_cnn_model.parameters(),\n",
    "                        lr=study_cnn.best_params['lr'],\n",
    "                        weight_decay=study_cnn.best_params['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "\n",
    "# Full training with best parameters\n",
    "epochs = 30\n",
    "best_val_acc = 0.0\n",
    "train_loader = DataLoader(train_dataset, batch_size=study_cnn.best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=study_cnn.best_params['batch_size'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(best_cnn_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate_epoch(best_cnn_model, val_loader, criterion, device)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(best_cnn_model.state_dict(), 'saved_models/best_cnn_model.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}: '\n",
    "          f'Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "          f'LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "# Load best model and evaluate\n",
    "best_cnn_model.load_state_dict(torch.load('saved_models/best_cnn_model.pth'))\n",
    "cnn_test_results = evaluate_on_test_with_metrics(best_cnn_model, test_loader, device, class_names, \"Best Tuned CNN\")\n",
    "\n",
    "# Enhanced visualization\n",
    "plot_confusion_matrix(cnn_test_results['confusion_matrix'], class_names, \"Best Tuned CNN\", cmap='plasma')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#ANN Tuning\n",
    "def objective_ann(trial):\n",
    "    \"\"\"Optuna objective function for ANN hyperparameter optimization.\"\"\"\n",
    "    # Define hyperparameters to optimize with expanded ranges\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    num_hidden_1 = trial.suggest_int(\"num_hidden_1\", 64, 512, step=64)\n",
    "    num_hidden_2 = trial.suggest_int(\"num_hidden_2\", 32, 256, step=32)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "\n",
    "    # Create data loaders with suggested batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    class TunedANN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_units, num_classes, dropout_rate):\n",
    "            super().__init__()\n",
    "            layers = []\n",
    "            in_features = input_size\n",
    "\n",
    "            # Dynamically create hidden layers\n",
    "            for i, units in enumerate(hidden_units):\n",
    "                layers.extend([\n",
    "                    nn.Linear(in_features, units),\n",
    "                    nn.BatchNorm1d(units),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                ])\n",
    "                in_features = units\n",
    "\n",
    "            layers.append(nn.Linear(in_features, num_classes))\n",
    "            self.network = nn.Sequential(*layers)\n",
    "            self._initialize_weights()\n",
    "\n",
    "        def _initialize_weights(self):\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x.view(x.size(0), -1))\n",
    "\n",
    "    # Initialize model with dynamic architecture\n",
    "    model = TunedANN(\n",
    "        flat_input_size,\n",
    "        [num_hidden_1, num_hidden_2],\n",
    "        num_classes,\n",
    "        dropout_rate\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "\n",
    "    # Training with early stopping\n",
    "    epochs = 15\n",
    "    best_val_accuracy = 0.0\n",
    "    patience = 3\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "    return best_val_accuracy\n",
    "\n",
    "# Train the best ANN model with full epochs\n",
    "class BestTunedANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, num_classes, dropout_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "\n",
    "        for units in hidden_units:\n",
    "            layers.extend([\n",
    "                nn.Linear(in_features, units),\n",
    "                nn.BatchNorm1d(units),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            in_features = units\n",
    "\n",
    "        layers.append(nn.Linear(in_features, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x.view(x.size(0), -1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create and run the study\n",
    "study_ann = optuna.create_study(direction=\"maximize\")\n",
    "study_ann.enqueue_trial({\n",
    "    'lr': 0.001,\n",
    "    'num_hidden_1': 128,\n",
    "    'num_hidden_2': 64,\n",
    "    'dropout': 0.2,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 128\n",
    "})\n",
    "\n",
    "# Optimize with pruning\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "study_ann.optimize(objective_ann, n_trials=20, timeout=3600)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest ANN hyperparameters:\", study_ann.best_params)\n",
    "print(\"Best validation accuracy:\", study_ann.best_value)\n",
    "\n",
    "# Visualization\n",
    "optuna.visualization.plot_optimization_history(study_ann).show()\n",
    "optuna.visualization.plot_param_importances(study_ann).show()\n",
    "\n",
    "# Initialize and train the best model\n",
    "best_params = study_ann.best_params\n",
    "best_ann_model = BestTunedANN(\n",
    "    flat_input_size,\n",
    "    [best_params['num_hidden_1'], best_params['num_hidden_2']],\n",
    "    num_classes,\n",
    "    best_params['dropout']\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(best_ann_model.parameters(),\n",
    "                        lr=best_params['lr'],\n",
    "                        weight_decay=best_params['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "\n",
    "# Full training with best parameters\n",
    "epochs = 30\n",
    "best_val_acc = 0.0\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(best_ann_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate_epoch(best_ann_model, val_loader, criterion, device)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(best_ann_model.state_dict(), 'saved_models/best_ann_model.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}: '\n",
    "          f'Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "          f'LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "# Load best model and evaluate\n",
    "best_ann_model.load_state_dict(torch.load('saved_models/best_ann_model.pth'))\n",
    "ann_test_results = evaluate_on_test_with_metrics(best_ann_model, test_loader, device, class_names, \"Best Tuned ANN\")\n",
    "\n",
    "# Enhanced visualization\n",
    "plot_confusion_matrix(ann_test_results['confusion_matrix'], class_names, \"Best Tuned ANN\", cmap='viridis')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Pretrained Model Tuning\n",
    "def objective_googlenet(trial):\n",
    "    \"\"\"Optuna objective function for GoogLeNet hyperparameter optimization.\"\"\"\n",
    "    # Define hyperparameters to optimize with expanded ranges\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    freeze_backbone = trial.suggest_categorical(\"freeze_backbone\", [True, False])\n",
    "\n",
    "    # Create data loaders with suggested batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = models.googlenet(weights='IMAGENET1K_V1')\n",
    "\n",
    "    # Freeze backbone if specified\n",
    "    if freeze_backbone:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify classifier head\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(num_ftrs, num_classes)\n",
    "    )\n",
    "\n",
    "    # Modify auxiliary classifiers if they exist\n",
    "    if hasattr(model, 'aux1') and model.aux1 is not None:\n",
    "        model.aux1.fc2 = nn.Linear(model.aux1.fc2.in_features, num_classes)\n",
    "    if hasattr(model, 'aux2') and model.aux2 is not None:\n",
    "        model.aux2.fc2 = nn.Linear(model.aux2.fc2.in_features, num_classes)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "\n",
    "    # Training with early stopping\n",
    "    epochs = 10\n",
    "    best_val_accuracy = 0.0\n",
    "    patience = 3\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "    return best_val_accuracy\n",
    "\n",
    "# Train the best GoogLeNet model with full epochs\n",
    "def initialize_best_googlenet(params, num_classes):\n",
    "    \"\"\"Initialize GoogLeNet with best parameters.\"\"\"\n",
    "    model = models.googlenet(weights='IMAGENET1K_V1')\n",
    "\n",
    "    if params['freeze_backbone']:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(params['dropout']),\n",
    "        nn.Linear(num_ftrs, num_classes)\n",
    "    )\n",
    "\n",
    "    # Modify auxiliary classifiers\n",
    "    if hasattr(model, 'aux1') and model.aux1 is not None:\n",
    "        model.aux1.fc2 = nn.Linear(model.aux1.fc2.in_features, num_classes)\n",
    "    if hasattr(model, 'aux2') and model.aux2 is not None:\n",
    "        model.aux2.fc2 = nn.Linear(model.aux2.fc2.in_features, num_classes)\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create and run the study\n",
    "study_googlenet = optuna.create_study(direction=\"maximize\")\n",
    "study_googlenet.enqueue_trial({\n",
    "    'lr': 1e-4,\n",
    "    'dropout': 0.4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 32,\n",
    "    'freeze_backbone': True\n",
    "})\n",
    "\n",
    "# Optimize with pruning\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=3)\n",
    "study_googlenet.optimize(objective_googlenet, n_trials=15, timeout=3600)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest GoogLeNet hyperparameters:\", study_googlenet.best_params)\n",
    "print(\"Best validation accuracy:\", study_googlenet.best_value)\n",
    "\n",
    "# Visualization\n",
    "optuna.visualization.plot_optimization_history(study_googlenet).show()\n",
    "optuna.visualization.plot_param_importances(study_googlenet).show()\n",
    "\n",
    "# Initialize and train the best model\n",
    "best_params = study_googlenet.best_params\n",
    "best_googlenet_model = initialize_best_googlenet(best_params, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(best_googlenet_model.parameters(),\n",
    "                        lr=best_params['lr'],\n",
    "                        weight_decay=best_params['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "\n",
    "# Full training with best parameters\n",
    "epochs = 20\n",
    "best_val_acc = 0.0\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(best_googlenet_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate_epoch(best_googlenet_model, val_loader, criterion, device)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(best_googlenet_model.state_dict(), 'saved_models/best_googlenet_model.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}: '\n",
    "          f'Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "          f'LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "# Load best model and evaluate\n",
    "best_googlenet_model.load_state_dict(torch.load('saved_models/best_googlenet_model.pth'))\n",
    "googlenet_test_results = evaluate_on_test_with_metrics(best_googlenet_model, test_loader, device, class_names, \"Best Tuned GoogLeNet\")\n",
    "\n",
    "# Enhanced visualization\n",
    "plot_confusion_matrix(googlenet_test_results['confusion_matrix'], class_names, \"Best Tuned GoogLeNet\", cmap='plasma')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a directory to save models if it doesn't exist\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Generate timestamp for versioning\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the best CNN model with versioning\n",
    "cnn_path = f\"saved_models/best_cnn_model.pth\"\n",
    "torch.save(best_cnn_model.state_dict(), cnn_path)\n",
    "\n",
    "# Save the best ANN model with versioning\n",
    "ann_path = f\"saved_models/best_ann_model.pth\"\n",
    "torch.save(best_ann_model.state_dict(), ann_path)\n",
    "\n",
    "# Save the best GoogLeNet model with versioning\n",
    "googlenet_path = f\"saved_models/best_googlenet_model.pth\"\n",
    "torch.save(best_googlenet_model.state_dict(), googlenet_path)\n",
    "\n",
    "# Create a metadata file\n",
    "metadata = {\n",
    "    'save_date': timestamp,\n",
    "    'models': {\n",
    "        'cnn': os.path.basename(cnn_path),\n",
    "        'ann': os.path.basename(ann_path),\n",
    "        'googlenet': os.path.basename(googlenet_path)\n",
    "    },\n",
    "    'performance': {\n",
    "        'cnn_accuracy': cnn_test_results['accuracy'],\n",
    "        'ann_accuracy': ann_test_results['accuracy'],\n",
    "        'googlenet_accuracy': googlenet_test_results['accuracy']\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = f\"saved_models/model_metadata_{timestamp}.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Models and metadata saved successfully:\")\n",
    "print(f\"- CNN: {cnn_path} (Accuracy: {cnn_test_results['accuracy']:.4f})\")\n",
    "print(f\"- ANN: {ann_path} (Accuracy: {ann_test_results['accuracy']:.4f})\")\n",
    "print(f\"- GoogLeNet: {googlenet_path} (Accuracy: {googlenet_test_results['accuracy']:.4f})\")\n",
    "print(f\"- Metadata: {metadata_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CNNRNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, freeze_backbone=True, rnn_hidden_size=384, feature_size=256):\n",
    "        \"\"\"Initialize a CNN-RNN hybrid model for image classification.\n",
    "        \n",
    "        Args:\n",
    "            num_classes (int): Number of output classes\n",
    "            freeze_backbone (bool): Whether to freeze CNN backbone weights (default: True)\n",
    "            rnn_hidden_size (int): Size of RNN hidden state (default: 384)\n",
    "            feature_size (int): Size of refined features before classification (default: 256)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Use EfficientNet with pretrained weights\n",
    "        self.backbone = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT).features\n",
    "\n",
    "        # Freeze backbone if specified\n",
    "        if freeze_backbone:\n",
    "            for param in list(self.backbone.parameters())[:10]:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Adaptive pooling to fixed size\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))  # Output: (B, 1536, 4, 4)\n",
    "\n",
    "        # Bidirectional GRU (better gradient flow than LSTM for many tasks)\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=1536,\n",
    "            hidden_size=rnn_hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Feature refinement layers with proper initialization\n",
    "        self.feature_refiner = nn.Sequential(\n",
    "            nn.Linear(2*rnn_hidden_size, 512),  # 2* for bidirectional\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(feature_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights for linear and GRU layers.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (B, 3, H, W)\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Output logits of shape (B, num_classes)\n",
    "        \"\"\"\n",
    "        # CNN Feature extraction\n",
    "        x = self.backbone(x)      # (B, 1536, H', W')\n",
    "        x = self.avgpool(x)       # (B, 1536, 4, 4)\n",
    "        x = x.flatten(2)          # (B, 1536, 16)\n",
    "        x = x.permute(0, 2, 1)    # (B, 16, 1536)\n",
    "\n",
    "        # RNN processing\n",
    "        rnn_out, _ = self.rnn(x)  # (B, 16, 2*rnn_hidden_size)\n",
    "\n",
    "        # Use mean pooling over sequence dimension (more stable than last hidden state)\n",
    "        pooled = rnn_out.mean(dim=1)  # (B, 2*rnn_hidden_size)\n",
    "\n",
    "        # Feature refinement\n",
    "        features = self.feature_refiner(pooled)  # (B, feature_size)\n",
    "\n",
    "        # Classification\n",
    "        return self.classifier(features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "num_classes = len(train_dataset.classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model with proper configuration\n",
    "cnn_rnn_model = CNNRNNClassifier(\n",
    "    num_classes=num_classes,\n",
    "    freeze_backbone=True,  # Keep pretrained features frozen initially\n",
    "    rnn_hidden_size=384,\n",
    "    feature_size=256\n",
    ").to(device)\n",
    "\n",
    "# Calculate class weights if imbalance exists\n",
    "class_counts = np.bincount([label for _, label in train_dataset])\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float32, device=device)\n",
    "class_weights = class_weights / class_weights.sum() * num_classes  # Normalize\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer with weight decay and gradient clipping\n",
    "optimizer = torch.optim.AdamW(\n",
    "    cnn_rnn_model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-5,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Learning rate scheduling with warmup\n",
    "warmup_epochs = 5\n",
    "total_epochs = 80\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    total_steps=total_epochs * len(train_loader),\n",
    "    pct_start=warmup_epochs/total_epochs,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Training tracking\n",
    "best_val_acc = 0.0\n",
    "no_improve = 0\n",
    "patience = 15\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(f\"Starting training on {device}...\")\n",
    "print(f\"Using {'class weights' if class_weights is not None else 'no class weighting'}\")\n",
    "print(f\"Model architecture:\\n{cnn_rnn_model}\")\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    # Training phase\n",
    "    cnn_rnn_model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{total_epochs} [Train]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = cnn_rnn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass with scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(cnn_rnn_model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Update weights\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update LR scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Track metrics\n",
    "        epoch_train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = epoch_train_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    cnn_rnn_model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{total_epochs} [Val]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = cnn_rnn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = epoch_val_loss / total_val\n",
    "    val_acc = correct_val / total_val\n",
    "\n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{total_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Acc: {val_acc*100:.2f}%\")\n",
    "    print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': cnn_rnn_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'train_loss': train_loss,\n",
    "        }, 'saved_models/best_cnn_rnn_model.pth')\n",
    "        print(f\"Validation accuracy improved to {val_acc*100:.2f}% - model saved\")\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {patience} epochs without improvement\")\n",
    "            break\n",
    "\n",
    "    # Gradually unfreeze backbone after warmup\n",
    "    if epoch == warmup_epochs:\n",
    "        for param in cnn_rnn_model.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"\\nUnfreezing backbone weights for fine-tuning\")\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train')\n",
    "plt.plot(history['val_acc'], label='Validation')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the best models\n",
    "# 1. CNN-RNN\n",
    "cnn_rnn_model = CNNRNNClassifier(num_classes).to(device)\n",
    "cnn_rnn_model.load_state_dict(torch.load('saved_models/best_cnn_rnn_model.pth')['model_state_dict'])\n",
    "\n",
    "# 2. CNN\n",
    "#best_cnn_model = BestTunedCNN(num_classes, study_cnn.best_params).to(device)\n",
    "#best_cnn_model.load_state_dict(torch.load('saved_models/best_cnn_model.pth'))\n",
    "\n",
    "# 3. ANN (SimpleANN)\n",
    "#best_ann_model = BestTunedANN(\n",
    "#    flat_input_size,\n",
    "#    [study_ann.best_params['num_hidden_1'], study_ann.best_params['num_hidden_2']],\n",
    "#    num_classes,\n",
    "#    study_ann.best_params['dropout']\n",
    "#).to(device)\n",
    "#best_ann_model.load_state_dict(torch.load('saved_models/best_ann_model.pth'))\n",
    "\n",
    "# 4. GoogLeNet\n",
    "#best_googlenet_model = initialize_best_googlenet(study_googlenet.best_params, num_classes).to(device)\n",
    "#best_googlenet_model.load_state_dict(torch.load('saved_models/best_googlenet_model.pth'))\n",
    "\n",
    "# Evaluate\n",
    "cnn_rnn_results = evaluate_on_test_with_metrics(\n",
    "    model=cnn_rnn_model,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    class_names=train_dataset.classes,\n",
    "    model_name=\"CNN-RNN Hybrid\"\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[CNN-RNN] Test Set Evaluation Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"- Accuracy: {cnn_rnn_results['accuracy']:.4f}\")\n",
    "print(f\"- Balanced Accuracy: {cnn_rnn_results['balanced_accuracy']:.4f}\")\n",
    "print(f\"- ROC AUC: {cnn_rnn_results['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(cnn_rnn_results['classification_report'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    cm=cnn_rnn_results['confusion_matrix'],\n",
    "    class_names=train_dataset.classes,\n",
    "    model_name=\"CNN-RNN Hybrid\",\n",
    "    cmap='magma'  # Using magma colormap for better visual distinction\n",
    ")\n",
    "\n",
    "# If you want to compare with other models, create a models_dict first\n",
    "models_dict = {\n",
    "    'CNN-RNN': cnn_rnn_model.state_dict(),\n",
    "    #'CNN': best_cnn_model.state_dict(),\n",
    "    #'SimpleANN': best_ann_model.state_dict(),\n",
    "    #'GoogLeNet': best_googlenet_model.state_dict()\n",
    "}\n",
    "\n",
    "test_results = evaluate_all_models(\n",
    "    models_dict=models_dict,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    class_names=train_dataset.classes,\n",
    "    img_size=128,\n",
    "    num_classes=num_classes\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 4: Deployment and Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Deployment"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "server = app.server\n",
    "\n",
    "# Define the layout\n",
    "app.layout = dbc.Container([\n",
    "    html.H1(\"Garbage Classification System\", className=\"text-center my-4\"),\n",
    "    html.Hr(),\n",
    "\n",
    "    # Instruction Section\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Div([\n",
    "                html.P(\"Upload an image of garbage to classify it into different categories. The system will predict the type of garbage with the highest confidence.\")\n",
    "            ], className=\"text-muted text-center mb-4\"),\n",
    "        ])\n",
    "    ]),\n",
    "\n",
    "    # Image upload section\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Upload(\n",
    "                id='upload-image',\n",
    "                children=html.Div([\n",
    "                    'Drag and Drop or ',\n",
    "                    html.A('Select an Image')\n",
    "                ]),\n",
    "                style={\n",
    "                    'width': '100%',\n",
    "                    'height': '120px',\n",
    "                    'lineHeight': '120px',\n",
    "                    'borderWidth': '2px',\n",
    "                    'borderStyle': 'dashed',\n",
    "                    'borderRadius': '10px',\n",
    "                    'textAlign': 'center',\n",
    "                    'margin': '20px',\n",
    "                    'backgroundColor': '#f4f7fa'\n",
    "                },\n",
    "                multiple=False\n",
    "            ),\n",
    "        ], width=12),\n",
    "    ]),\n",
    "\n",
    "    # Image display and classification results\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Div(id='output-image-upload'),\n",
    "        ], width=6),\n",
    "\n",
    "        dbc.Col([\n",
    "            html.Div(id='classification-results',\n",
    "                     style={'marginTop': '20px'}),\n",
    "            dcc.Loading(\n",
    "                id=\"loading-results\",\n",
    "                type=\"circle\",\n",
    "                children=html.Div(id=\"loading-output\")\n",
    "            )\n",
    "        ], width=6),\n",
    "    ]),\n",
    "\n",
    "    # Footer\n",
    "    html.Hr(),\n",
    "    html.Footer(\"Garbage Classification System © 2025\",\n",
    "                className=\"text-center text-muted py-3\")\n",
    "], fluid=True)\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(contents):\n",
    "    try:\n",
    "        # Decode the base64 image\n",
    "        img_str = contents.split(\",\")[1]\n",
    "        img_bytes = base64.b64decode(img_str)\n",
    "        img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "\n",
    "        # Define transformations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Apply transformations and add batch dimension\n",
    "        img_tensor = transform(img).unsqueeze(0)\n",
    "        return img_tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Callback for image upload and classification\n",
    "@app.callback(\n",
    "    [Output('output-image-upload', 'children'),\n",
    "     Output('classification-results', 'children')],\n",
    "    [Input('upload-image', 'contents')],\n",
    "    [State('upload-image', 'filename')]\n",
    ")\n",
    "def update_output(contents, filename):\n",
    "    if contents is None:\n",
    "        return [html.Div(\"No image uploaded yet.\"), \"\"]\n",
    "\n",
    "    # Display the uploaded image\n",
    "    img_html = html.Div([\n",
    "        html.H5(filename),\n",
    "        html.Img(src=contents, style={'height': '300px', 'width': 'auto'}),\n",
    "        html.Hr()\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    img_tensor = preprocess_image(contents)\n",
    "    if img_tensor is None:\n",
    "        return [img_html, html.Div(\"Error processing image.\", className=\"text-danger\")]\n",
    "\n",
    "    # Move to device and predict\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = cnn_rnn_model(img_tensor)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        conf, preds = torch.max(probs, 1)\n",
    "\n",
    "    # Get class name and confidence\n",
    "    class_name = train_dataset.classes[preds.item()]\n",
    "    confidence = conf.item() * 100\n",
    "\n",
    "    # Create results display in a card format\n",
    "    results = dbc.Card([\n",
    "        dbc.CardHeader(\"Classification Results\", className=\"bg-primary text-white\"),\n",
    "        dbc.CardBody([\n",
    "            html.H4(f\"Predicted Class: {class_name}\", className=\"card-title\"),\n",
    "            html.P(f\"Confidence: {confidence:.2f}%\", className=\"card-text\"),\n",
    "            html.Hr(),\n",
    "            html.H5(\"Class Probabilities:\"),\n",
    "            html.Ul([\n",
    "                html.Li(f\"{train_dataset.classes[i]}: {probs[0][i].item()*100:.2f}%\")\n",
    "                for i in range(len(train_dataset.classes))\n",
    "            ])\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "    return [img_html, results]  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define number of output classes and device\n",
    "    num_classes = len(train_dataset.classes)  # or set it manually if dataset isn't loaded here\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Instantiate and load the CNN-RNN model\n",
    "    cnn_rnn_model = CNNRNNClassifier(num_classes=num_classes).to(device)\n",
    "    cnn_rnn_model.load_state_dict(torch.load('saved_models/best_cnn_rnn_model.pth')['model_state_dict'])\n",
    "    cnn_rnn_model.eval()\n",
    "\n",
    "    # Run the Dash app in an external browser\n",
    "    app.run(debug=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# go to http://127.0.0.1:8050/",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Monitoring"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Dash app (if not already initialized)\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Setup for Model Monitor\n",
    "class ModelMonitor:\n",
    "    def __init__(self, reference_data, model, class_names):\n",
    "        \"\"\"\n",
    "        Initialize the monitoring system\n",
    "        \n",
    "        Args:\n",
    "            reference_data: DataFrame containing training data statistics\n",
    "            model: The trained model to monitor\n",
    "            class_names: List of class names\n",
    "        \"\"\"\n",
    "        self.reference_data = reference_data\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.production_data = pd.DataFrame(columns=['timestamp', 'image_hash', 'prediction',\n",
    "                                                     'confidence', 'true_label'])\n",
    "        self.performance_metrics = pd.DataFrame(columns=['timestamp', 'accuracy', 'precision',\n",
    "                                                         'recall', 'f1'])\n",
    "\n",
    "        # Initialize drift detectors\n",
    "        self.drift_detectors = {\n",
    "            'ks_test': {'threshold': 0.05},\n",
    "            'wasserstein': {'threshold': 0.1}\n",
    "        }\n",
    "\n",
    "        # Connect to MLflow\n",
    "        mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "        self.experiment_name = \"garbage_classification_monitoring\"\n",
    "        try:\n",
    "            mlflow.create_experiment(self.experiment_name)\n",
    "        except:\n",
    "            pass\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_prediction(self, image, prediction, confidence, true_label=None):\n",
    "        \"\"\"Log a prediction for monitoring\"\"\"\n",
    "        # Create image fingerprint (simplified)\n",
    "        img_hash = hash(np.array(image).tobytes())\n",
    "\n",
    "        # Record the prediction\n",
    "        new_entry = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'image_hash': img_hash,\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'true_label': true_label\n",
    "        }\n",
    "\n",
    "        self.production_data = self.production_data.append(new_entry, ignore_index=True)\n",
    "\n",
    "        # Log to MLflow\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_metric(\"prediction_confidence\", confidence)\n",
    "            mlflow.log_param(\"predicted_class\", self.class_names[prediction])\n",
    "            if true_label is not None:\n",
    "                mlflow.log_param(\"true_class\", self.class_names[true_label])\n",
    "                mlflow.log_metric(\"correct\", int(prediction == true_label))\n",
    "\n",
    "    def calculate_performance(self):\n",
    "        \"\"\"Calculate current performance metrics\"\"\"\n",
    "        if len(self.production_data) < 10:  # Need minimum samples\n",
    "            return None\n",
    "        # Get records with ground truth\n",
    "        valid_records = self.production_data.dropna(subset=['true_label'])\n",
    "        if len(valid_records) == 0:\n",
    "            return None\n",
    "\n",
    "        y_true = valid_records['true_label']\n",
    "        y_pred = valid_records['prediction']\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "        precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "        recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "        # Update performance history\n",
    "        new_metrics = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': 2 * (precision * recall) / (precision + recall)\n",
    "        }\n",
    "\n",
    "        self.performance_metrics = self.performance_metrics.append(new_metrics, ignore_index=True)\n",
    "        return new_metrics\n",
    "\n",
    "    def detect_drift(self, current_batch):\n",
    "        \"\"\"Detect data drift between reference and current data\"\"\"\n",
    "        drift_results = {}\n",
    "\n",
    "        # 1. Feature-level drift (using image statistics)\n",
    "        ref_stats = self.reference_data[['mean_pixel', 'std_pixel']]\n",
    "        curr_stats = current_batch[['mean_pixel', 'std_pixel']]\n",
    "\n",
    "        for stat in ['mean_pixel', 'std_pixel']:\n",
    "            ks_stat, ks_p = ks_2samp(ref_stats[stat], curr_stats[stat])\n",
    "            w_dist = wasserstein_distance(ref_stats[stat], curr_stats[stat])\n",
    "\n",
    "            drift_results[stat] = {\n",
    "                'ks_statistic': ks_stat,\n",
    "                'ks_pvalue': ks_p,\n",
    "                'wasserstein': w_dist,\n",
    "                'drift_detected': ks_p < self.drift_detectors['ks_test']['threshold'] or\n",
    "                                  w_dist > self.drift_detectors['wasserstein']['threshold']\n",
    "            }\n",
    "\n",
    "        # 2. Prediction drift (distribution of predicted classes)\n",
    "        ref_pred_dist = self.reference_data['class_distribution']\n",
    "        curr_pred_dist = current_batch['prediction'].value_counts(normalize=True)\n",
    "\n",
    "        for class_name in self.class_names:\n",
    "            ks_stat, ks_p = ks_2samp(\n",
    "                ref_pred_dist[class_name],\n",
    "                curr_pred_dist.get(class_name, 0)\n",
    "            )\n",
    "\n",
    "            drift_results[f'class_{class_name}'] = {\n",
    "                'ks_statistic': ks_stat,\n",
    "                'ks_pvalue': ks_p,\n",
    "                'drift_detected': ks_p < self.drift_detectors['ks_test']['threshold']\n",
    "            }\n",
    "\n",
    "        # Log drift metrics\n",
    "        with mlflow.start_run():\n",
    "            for metric, values in drift_results.items():\n",
    "                if 'drift_detected' in values:\n",
    "                    mlflow.log_metric(f\"{metric}_drift\", int(values['drift_detected']))\n",
    "                if 'ks_pvalue' in values:\n",
    "                    mlflow.log_metric(f\"{metric}_ks_pvalue\", values['ks_pvalue'])\n",
    "                if 'wasserstein' in values:\n",
    "                    mlflow.log_metric(f\"{metric}_wasserstein\", values['wasserstein'])\n",
    "\n",
    "        return drift_results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Performance Monitoring Dashboard Component\n",
    "def create_performance_monitoring():\n",
    "    \"\"\"Create a performance monitoring dashboard component\"\"\"\n",
    "    return dbc.Card([\n",
    "        dbc.CardHeader(\"Model Performance Monitoring\", className=\"bg-primary text-white\"),\n",
    "        dbc.CardBody([\n",
    "            dcc.Graph(id='accuracy-trend'),\n",
    "            dcc.Graph(id='confusion-matrix'),\n",
    "            dcc.Interval(id='update-interval', interval=60*1000, n_intervals=0)  # Update every minute\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "# Data Drift Detection Dashboard Component\n",
    "def create_drift_detection():\n",
    "    \"\"\"Create a data drift detection dashboard component\"\"\"\n",
    "    return dbc.Card([\n",
    "        dbc.CardHeader(\"Data Drift Detection\", className=\"bg-warning text-dark\"),\n",
    "        dbc.CardBody([\n",
    "            dcc.Graph(id='feature-drift'),\n",
    "            dcc.Graph(id='prediction-drift'),\n",
    "            html.Div(id='drift-alerts')\n",
    "        ])\n",
    "    ])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Layout for Dash app\n",
    "app.layout = dbc.Container([\n",
    "    # Add performance monitoring dashboard\n",
    "    dbc.Row([dbc.Col(create_performance_monitoring(), width=12)], className=\"my-4\"),\n",
    "    # Add drift detection dashboard\n",
    "    dbc.Row([dbc.Col(create_drift_detection(), width=12)], className=\"my-4\"),\n",
    "])\n",
    "\n",
    "# Callback for performance monitoring\n",
    "@app.callback(\n",
    "    [Output('accuracy-trend', 'figure'),\n",
    "     Output('confusion-matrix', 'figure')],\n",
    "    [Input('update-interval', 'n_intervals')]\n",
    ")\n",
    "def update_performance(n):\n",
    "    # Get recent performance data (last 7 days)\n",
    "    recent_data = monitor.performance_metrics[\n",
    "        monitor.performance_metrics['timestamp'] > (datetime.now() - pd.Timedelta(days=7))]\n",
    "\n",
    "    # Create accuracy trend plot\n",
    "    acc_fig = go.Figure()\n",
    "    acc_fig.add_trace(go.Scatter(\n",
    "        x=recent_data['timestamp'],\n",
    "        y=recent_data['accuracy'],\n",
    "        mode='lines+markers',\n",
    "        name='Accuracy'\n",
    "    ))\n",
    "    acc_fig.update_layout(title='Accuracy Over Time', yaxis=dict(range=[0, 1]))\n",
    "\n",
    "    # Create confusion matrix plot\n",
    "    cm = confusion_matrix(\n",
    "        monitor.production_data['true_label'].dropna(),\n",
    "        monitor.production_data['prediction'].dropna(),\n",
    "        normalize='true'\n",
    "    )\n",
    "    cm_fig = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=monitor.class_names,\n",
    "        y=monitor.class_names,\n",
    "        colorscale='Blues'\n",
    "    ))\n",
    "    cm_fig.update_layout(title='Normalized Confusion Matrix')\n",
    "\n",
    "    return acc_fig, cm_fig\n",
    "\n",
    "# Callback for drift detection\n",
    "@app.callback(\n",
    "    [Output('feature-drift', 'figure'),\n",
    "     Output('prediction-drift', 'figure'),\n",
    "     Output('drift-alerts', 'children')],\n",
    "    [Input('update-interval', 'n_intervals')]\n",
    ")\n",
    "def update_drift(n):\n",
    "    # Get recent production data (last 24 hours)\n",
    "    recent_data = monitor.production_data[\n",
    "        monitor.production_data['timestamp'] > (datetime.now() - pd.Timedelta(hours=24))]\n",
    "\n",
    "    if len(recent_data) == 0:\n",
    "        return go.Figure(), go.Figure(), \"No data available for drift detection\"\n",
    "\n",
    "    # Calculate drift\n",
    "    drift_results = monitor.detect_drift(recent_data)\n",
    "\n",
    "    # Create feature drift plot\n",
    "    feature_fig = go.Figure()\n",
    "    feature_fig.add_trace(go.Bar(\n",
    "        x=['Mean Pixel', 'Std Pixel'],\n",
    "        y=[drift_results['mean_pixel']['wasserstein'],\n",
    "           drift_results['std_pixel']['wasserstein']],\n",
    "        name='Wasserstein Distance'\n",
    "    ))\n",
    "    feature_fig.update_layout(title='Feature Distribution Drift')\n",
    "\n",
    "    # Create prediction drift plot\n",
    "    pred_fig = go.Figure()\n",
    "    for class_name in monitor.class_names:\n",
    "        pred_fig.add_trace(go.Bar(\n",
    "            x=[class_name],\n",
    "            y=[drift_results[f'class_{class_name}']['ks_pvalue']],\n",
    "            name=class_name\n",
    "        ))\n",
    "    pred_fig.update_layout(title='Prediction Distribution Drift (KS p-values)')\n",
    "\n",
    "    # Create alerts\n",
    "    drift_alerts = []\n",
    "    for feature, result in drift_results.items():\n",
    "        if result.get('drift_detected', False):\n",
    "            alert = dbc.Alert(\n",
    "                f\"Drift detected in {feature} (p={result['ks_pvalue']:.3f})\",\n",
    "                color=\"danger\",\n",
    "                dismissable=True,\n",
    "                className=\"my-2\"\n",
    "            )\n",
    "            drift_alerts.append(alert)\n",
    "\n",
    "    return feature_fig, pred_fig, drift_alerts if drift_alerts else \"No significant drift detected\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize monitoring system (ensure reference data is available)\n",
    "reference_stats = pd.read_csv('reference_data_stats.csv')  # Pre-computed from training data\n",
    "monitor = ModelMonitor(reference_stats, cnn_rnn_model, train_dataset.classes)\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
